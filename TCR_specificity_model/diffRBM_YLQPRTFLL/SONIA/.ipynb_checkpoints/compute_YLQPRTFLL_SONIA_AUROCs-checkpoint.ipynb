{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55c11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../apps/SONIA')\n",
    "sys.path.append('../../apps/OLGA')\n",
    "sys.path.append('../../apps/soNNia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721ec4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from os.path import exists\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b87ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonnia.sonnia import SoNNia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce287352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb686e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "pep = \"YLQPRTFLL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c380aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare emerson sequences for SONIA\n",
    "train_seqs_df = pd.read_csv('./train_train_WithoutDuplicates_aligned_20.csv.gz')\n",
    "t_seqs = train_seqs_df['amino_acid'].to_list()\n",
    "t_v = train_seqs_df['v_gene'].to_list()\n",
    "t_j = train_seqs_df['j_gene'].to_list()\n",
    "sonia_input_emerson = [list(a) for a in zip(t_seqs, t_v, t_j)]\n",
    "\n",
    "# select subset of 10^6 seqs\n",
    "n_max = 1000000\n",
    "raninds = np.arange(len(sonia_input_emerson))\n",
    "rng = np.random.default_rng(2021)\n",
    "rng.shuffle(raninds)\n",
    "raninds = raninds[:n_max]\n",
    "sonia_input_emerson_1e6 = list(np.array(sonia_input_emerson)[raninds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6f32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare peptide-specific seqs for SONIA\n",
    "vdgdb_df = pd.read_csv('./' + pep + '/VDJdb_' + pep + '_WithAligned20.csv')\n",
    "vdgdb_df = vdgdb_df.drop_duplicates().reset_index(drop=True)\n",
    "t_seqs = vdgdb_df['CDR3_beta'].to_list()\n",
    "t_v = vdgdb_df['TRBV_gene'].to_list()\n",
    "t_j = vdgdb_df['TRBJ_gene'].to_list()\n",
    "sonia_input_vdgdb = [list(a) for a in zip(t_seqs, t_v, t_j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "310af913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare second set of Emerson seqs for SONIA (to be used as negative)\n",
    "filename_cdr3raw = './train_data_1.txt' \n",
    "inds_non_overlap = np.loadtxt('./1_inds_nonoverlap_0.txt').astype(np.int16)\n",
    "t_seq0 = []\n",
    "with open(filename_cdr3raw) as f:\n",
    "    for line in f:\n",
    "        linesplit = line.strip().split('\\n')\n",
    "        t_seq0.append(linesplit[0])\n",
    "\n",
    "t_seq = [x.split('\\t') for x in np.array(t_seq0)[inds_non_overlap]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad69e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3968.253968253968"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sonia_input_emerson_1e6) / int(80*len(sonia_input_vdgdb)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e5a79a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings2 \n",
    "l2_fin = 0\n",
    "epo = 30\n",
    "bs = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e32cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 252/252 [00:00<00:00, 6369.33it/s]\n",
      "  0%|          | 643/1000000 [00:00<02:35, 6424.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode data.\n",
      "Encode gen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 322406/1000000 [00:24<00:49, 13756.38it/s]"
     ]
    }
   ],
   "source": [
    "# main computation: AUROCs\n",
    "\n",
    "if exists('./' + pep + '/AUROCs.txt'):\n",
    "    AUROCs = np.loadtxt('./' + pep + '/AUROCs.txt')\n",
    "else:\n",
    "    AUROCs = []\n",
    "for i in range(len(AUROCs), 50):\n",
    "    repl = i\n",
    "    \n",
    "    ## prepare positives (train, test) ##\n",
    "    path_o ='./' + pep + '/indices/index_permutation_repl' + str(repl) + '.txt'\n",
    "    full_intR = (np.loadtxt(path_o)).astype(np.int16)\n",
    "    data = [sonia_input_vdgdb[t] for t in full_intR]\n",
    "    train_data = data[:int(80*len(data)/100)]\n",
    "    val_data = data[int(80*len(data)/100):]\n",
    "\n",
    "    ## prepare negatives (test) ##\n",
    "    path_o ='./' + pep + '/indices/index_permutationN_repl' + str(repl) + '.txt'\n",
    "    full_intR = (np.loadtxt(path_o)).astype(np.int16)\n",
    "    val_dataN0 = [t_seq[t] for t in full_intR]\n",
    "    val_dataN = val_dataN0[:len(val_data)]\n",
    "    \n",
    "    ## train model ##\n",
    "    qm = SoNNia(data_seqs = train_data, \n",
    "            gen_seqs = sonia_input_emerson_1e6,\n",
    "            l2_reg = l2_fin,\n",
    "            deep=False, include_joint_genes=True, include_indep_genes=False,\n",
    "            )\n",
    "    qm.infer_selection(epochs = epo, batch_size = bs, validation_split=0.01, verbose=0)\n",
    "    \n",
    "    ## check for nans ##\n",
    "    t_min = np.min(qm.likelihood_train)\n",
    "    if np.isnan(t_min):\n",
    "        print(\"ERROR: nan obtained! Try to have a larger minibatch to prevent this...\")\n",
    "        AUROCs.append(-1)\n",
    "    \n",
    "    ## compute AUROCz ##\n",
    "    LR_vdgdbn = [qm.find_seq_features(x) for x in val_data]\n",
    "    LR_emerson = [qm.find_seq_features(x) for x in val_dataN]\n",
    "    scores_positive = - qm.compute_energy(LR_vdgdbn)\n",
    "    scores_negative = - qm.compute_energy(LR_emerson)    \n",
    "    labels = np.hstack((np.zeros((len(scores_negative))), np.ones((len(scores_positive))))) \n",
    "    scores = np.hstack((scores_negative, scores_positive))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(labels, scores)\n",
    "    AUROCs = np.append(AUROCs, metrics.auc(fpr, tpr))\n",
    "    \n",
    "    # save resulting AUROC file (this rewrites the file completely, but it is a short file so no problem...)\n",
    "    np.savetxt('./' + pep + '/AUROCs.txt', AUROCs)\n",
    "    \n",
    "    # save resulting positives_scores\n",
    "    np.savetxt('./' + pep + '/scores_positives_' + str(i) + '.txt', scores_positive)\n",
    "    \n",
    "    # save resulting negatives_scores\n",
    "    np.savetxt('./' + pep + '/scores_negatives_' + str(i) + '.txt', scores_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cc630",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUROCs = np.loadtxt('./' + pep + '/AUROCs.txt')\n",
    "AUROCs.mean(), AUROCs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f9c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
