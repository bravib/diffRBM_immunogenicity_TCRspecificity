{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we produce the results related to the diffRBM model \n",
    "of TCR specificity (Figs. 5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inclusions ###\n",
    "\n",
    "rootf = ... ## Your folder ##\n",
    "# put here the folder where all subfolders (diffRBM, Align utils, TCR_specificity_model etc. are saved)\n",
    "\n",
    "import sys, os, pickle\n",
    "sys.path.append('/home/barbara/.local/lib/python3.9/site-packages/')\n",
    "sys.path.append(rootf)\n",
    "sys.path.append(rootf + '/diffRBM/source/')\n",
    "sys.path.append(rootf + '/diffRBM/utilities/')\n",
    "\n",
    "import diffrbm\n",
    "import csv\n",
    "import utilities as utilities\n",
    "import rbm as rbm\n",
    "import diffrbm as diffrbm\n",
    "\n",
    "import dataset_utils, RBM_utils, evaluate_learning_utils\n",
    "import utilities, sequence_logo,plots_utils\n",
    "import Proteins_utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import utilities_diffrbm\n",
    "\n",
    "# Plots stuff\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import patches\n",
    "from pandas.plotting import table\n",
    "mpl.rcParams['font.family'] = ['Garuda']\n",
    "mpl.rcParams['font.serif'] = ['Garuda-Oblique']\n",
    "\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy.optimize import fsolve\n",
    "import math\n",
    "\n",
    "## A series of useful functions ##\n",
    "\n",
    "def overlap_seqs(list1,list2):\n",
    "    overlap=[]\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] in list2:\n",
    "            overlap.append(list1[i])\n",
    "    return overlap\n",
    "\n",
    "def align_seqs(all_cdr3,SA,SAmin,SAmax):\n",
    "    import subprocess, os\n",
    "    name_mat = rootf + '/Align_utils/align_protpy.py'\n",
    "    all_seqs1 = list(all_cdr3)\n",
    "    name_seed = rootf + '/Align_utils/prots_seed.txt'\n",
    "    with open(name_seed, 'w') as out_f:\n",
    "        for u in range(len(all_seqs1)):\n",
    "            if len(all_seqs1[u]) >= SAmin:  \n",
    "                out_f.write(all_seqs1[u] + '\\n')\n",
    "                \n",
    "    subprocess.call('python3 ' + name_mat + ' -ss ' + name_seed + ' -SA ' + str(SA) + ' -SAmin ' + str(SAmin) + ' -SAmax ' + str(SAmax), shell = True)\n",
    "    seqs_al = np.loadtxt(rootf + '/Align_utils/aligned_prot.txt')\n",
    "    os.system('rm ' + rootf + '/Align_utils/aligned_prot.txt')\n",
    "    \n",
    "    return seqs_al\n",
    "\n",
    "def align_seqs_seed(seed_seqs,new_seqs,SA,SAmin,SAmax):\n",
    "    \n",
    "    import subprocess, os\n",
    "    name_mat = rootf + '/Align_utils/align_prot_to_seedpy.py'\n",
    "    \n",
    "    all_seqs1 = list(seed_seqs)\n",
    "    name_seed = rootf + '/Align_utils/prots_seed.txt'\n",
    "    with open(name_seed, 'w') as out_f:\n",
    "        for u in range(len(all_seqs1)):\n",
    "            if len(all_seqs1[u]) >= SAmin:  \n",
    "                out_f.write(all_seqs1[u] + '\\n')\n",
    "                \n",
    "    seqs_gapless = list(new_seqs)\n",
    "    name_seqs = rootf + '/Align_utils/prots_seqs.txt'\n",
    "    with open(name_seqs, 'w') as out_f:\n",
    "        for u in range(len(seqs_gapless)):\n",
    "            if len(seqs_gapless[u]) >= SAmin:  \n",
    "                out_f.write(seqs_gapless[u] + '\\n')\n",
    "                \n",
    "    subprocess.call('python3 ' + name_mat + ' -sseed ' + name_seed + ' -sseqs ' + name_seqs + ' -SA ' + str(SA) + ' -SAmin ' + str(SAmin) + ' -SAmax ' + str(SAmax) + ' -yw 0', shell = True)\n",
    "    seqs_al = np.loadtxt(rootf + '/Align_utils/aligned_prot.txt')\n",
    "    os.system('rm ' + rootf + '/Align_utils/aligned_prot.txt')\n",
    "    \n",
    "    return seqs_al\n",
    "\n",
    "def flatten_list(listoflist):\n",
    "    listoflist_fl = [];\n",
    "    for l in range(len(listoflist)):\n",
    "        for u in range(len(listoflist[l])):\n",
    "            listoflist_fl.append(listoflist[l][u])\n",
    "    return listoflist_fl\n",
    " \n",
    "curr_int = np.int16\n",
    "def convert_number(seqs): # convert to numbers already aligned seqs\n",
    "    aa = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V',  'W', 'Y','-']\n",
    "    aadict = {aa[k]: k for k in range(len(aa))} \n",
    "    \n",
    "    msa_num = np.array(list(map(lambda x: [aadict[y] for y in x], seqs[0:])), dtype=curr_int, order=\"c\") ### Here change ####\n",
    "    \n",
    "    return msa_num\n",
    "\n",
    "def uniqueIndexes(l):\n",
    "    seen = set()\n",
    "    res = []\n",
    "    for i, n in enumerate(l):\n",
    "        if n not in seen:\n",
    "            res.append(i)\n",
    "            seen.add(n)\n",
    "    return res\n",
    "\n",
    "def convert_letter(seqs_n): # convert to numbers already aligned seqs\n",
    "    aa = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V',  'W', 'Y','-']\n",
    "    aadictinv = {k: aa[k] for k in range(len(aa))} \n",
    "    seqs=[]\n",
    "    if type(seqs_n[0]) == curr_int:\n",
    "        seqs.append(''.join([aadictinv[e] for e in seqs_n]))\n",
    "    else:\n",
    "        for t in range(len(seqs_n)):\n",
    "            seqs.append(''.join([aadictinv[e] for e in seqs_n[t]]))\n",
    "    return seqs\n",
    "\n",
    "def produce_callback_weights(RBMdiff):\n",
    "    def callback():\n",
    "        RBMdiff.RBMpost.weights[RBMdiff.n_h_:] = 0\n",
    "    return callback\n",
    "\n",
    "def loglikelihood_indip_model(fields, logZ, seqs):\n",
    "    return fields[np.arange(len(fields)), seqs].sum(axis=1) - logZ\n",
    "\n",
    "def add_pseudocount(fields, n):\n",
    "    return np.array([(f + 1/n) / np.sum((f + 1/n)) for f in fields])\n",
    "\n",
    "def regularized_pwm(emp_freqsF, l2, pc):\n",
    "    \n",
    "    fields=[]\n",
    "    pwmi=[]\n",
    "    for ff in range(len(emp_freqsF)):\n",
    "        def equations(x):\n",
    "            return [(math.exp(x[i])/sum([math.exp(x[i]) for i in range(len(x))]) + l2*x[i] - emp_freqs[i]) for i in range(len(x))]\n",
    "        emp_freqs = np.copy(emp_freqsF[ff])\n",
    "        init = [np.log(c + pc) for c in emp_freqs]\n",
    "        fields0 = fsolve(equations, init)\n",
    "        pwmi0 = [math.exp(fields0[j])/sum([math.exp(fields0[i]) for i in range(len(fields0))]) for j in range(len(fields0))]\n",
    "        \n",
    "        fields.append(list(fields0))\n",
    "        pwmi.append(pwmi0)\n",
    "        \n",
    "    fields=np.array(fields)\n",
    "    pwmi=np.array(pwmi)\n",
    "        \n",
    "    return (fields, pwmi)\n",
    "\n",
    "def regularized_diffpwm(emp_freqsF, l2, pc, fields_backF):\n",
    "    \n",
    "    fields=[]\n",
    "    pwmi=[]\n",
    "    for ff in range(len(emp_freqsF)):\n",
    "        emp_freqs = np.copy(emp_freqsF[ff])\n",
    "        fields_back = np.copy(fields_backF[ff])\n",
    "        \n",
    "        def equations(x):\n",
    "            return [(math.exp(x[i] + fields_back[i])/sum([math.exp(x[i] + fields_back[i]) for i in range(len(x))]) + l2*(x[i]+ fields_back[i]) - emp_freqs[i]) for i in range(len(x))]\n",
    "        \n",
    "        \n",
    "        init = [np.log(c + pc) for c in emp_freqs]\n",
    "        fields0 = fsolve(equations, init)\n",
    "        pwmi0 = [math.exp(fields0[j] + fields_back[j])/sum([math.exp(fields0[i] + fields_back[i]) for i in range(len(fields0))]) for j in range(len(fields0))]\n",
    "        \n",
    "        fields.append(list(fields0))\n",
    "        pwmi.append(pwmi0)\n",
    "        \n",
    "    fields_top = np.array(fields)\n",
    "    pwmi_top = np.array(pwmi)\n",
    "        \n",
    "    return (fields_top, pwmi_top)\n",
    "\n",
    "import copy\n",
    "def site_conservation_scores(RBM, seq, A=20, L=9):\n",
    "    F = np.zeros((L, A))\n",
    "    for i in range(L):\n",
    "        for a in range(A):\n",
    "            v = copy.copy(seq)\n",
    "            v[i] = a\n",
    "            F[i,a] = RBM.free_energy(v)\n",
    "    return F.mean(1) - RBM.free_energy(v)\n",
    "\n",
    "def gene_to_num_str(gene_name, gene_type):\n",
    "    \"\"\"Strips excess gene name info to number string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gene_name : str\n",
    "        Gene or allele name\n",
    "    gene_type : char\n",
    "        Genomic cassette type. (i.e. V, D, or J)\n",
    "    Returns\n",
    "    -------\n",
    "    num_str : str\n",
    "        Reduced gene or allele name with leading zeros and excess\n",
    "        characters removed.\n",
    "\n",
    "    \"\"\"\n",
    "    # get rid of allele\n",
    "    gene_name=gene_name.split('*')[0]\n",
    "    num_str = gene_type.lower().join([g.lstrip('0') for g in gene_name.lower().split(gene_type.lower())[1:]])\n",
    "    num_str = '-'.join([g.lstrip('0') for g in num_str.split('-')])\n",
    "    return gene_type.lower() + num_str.replace('/', '')\n",
    "\n",
    "def shorten_gene_name(gene):\n",
    "    \"\"\"Removes 0 in gene name when not needed.\"\"\"\n",
    "    pre = gene[:4]\n",
    "    first_num = str(int(gene[4:6]))\n",
    "    if len(gene[6:]) == 0:\n",
    "        short_gene = pre + first_num\n",
    "    else:\n",
    "        dash = gene[6:7]\n",
    "        second_num = str(int(gene[7:]))\n",
    "        short_gene = pre + first_num + dash + second_num\n",
    "    return short_gene\n",
    "\n",
    "def add_VJ_info_2num(seqs_2num, V_list, J_list, V_dict, J_dict):\n",
    "    Vlist_2num = np.array([V_dict[v] for v in V_list]).reshape((seqs_2num.shape[0], 1))\n",
    "    Jlist_2num = np.array([J_dict[j] for j in J_list]).reshape((seqs_2num.shape[0], 1))\n",
    "    seqs_2num_VJ = np.append(seqs_2num, Vlist_2num, axis=1)\n",
    "    seqs_2num_VJ = np.append(seqs_2num_VJ, Jlist_2num, axis=1)\n",
    "    return seqs_2num_VJ\n",
    "\n",
    "\n",
    "def extract_data(pepN):\n",
    "\n",
    "    dataset = 'diffRBM_'+ pepN ## This is the name of the folder with the model; if does not exist I create it \n",
    "    name_folder = rootf + '/TCR_specificity_model/' + dataset\n",
    "    # load JV2num dicts\n",
    "    t_df = pd.read_csv(name_folder + '/J2num_dict_train_train.csv')\n",
    "    J2num_dict = dict(zip(t_df['J_gene'], t_df['RBM_VU_id']))\n",
    "    t_df = pd.read_csv(name_folder + '/V2num_dict_train_train.csv')\n",
    "    V2num_dict = dict(zip(t_df['V_gene'], t_df['RBM_VU_id']))\n",
    "    vdgdb_df = pd.read_csv(rootf + '/TCR_specificity_model/diffRBM_' + pepN + '/VDJdb_' + pepN + '_WithAligned20.csv')\n",
    "    train_datan = vdgdb_df.drop_duplicates().reset_index(drop=True)\n",
    "    # do num2seq\n",
    "    t_trainseq = train_datan[\"ali_seq\"].to_list()\n",
    "    trainseq_2num = np.array(Proteins_utils.seq2num(t_trainseq), dtype=np.int16)\n",
    "    # add to gen_seqs2num two integers for each row, obtained from V and J\n",
    "    Vlist = train_datan[\"TRBV_gene\"].to_list()\n",
    "    Jlist = train_datan[\"TRBJ_gene\"].to_list()\n",
    "    train_2num_withVJ = add_VJ_info_2num(trainseq_2num, Vlist, Jlist, V2num_dict, J2num_dict)\n",
    "    if makeVJ:\n",
    "        train_dataBIvn = np.copy(train_2num_withVJ)\n",
    "    else:\n",
    "        train_dataBIvn = np.copy(train_2num_withVJ[:,:-2])\n",
    "\n",
    "    return train_dataBIvn\n",
    "\n",
    "def regularized_pwm_torch(freqs, l2, n_iter = 1000):\n",
    "    g = torch.zeros_like(freqs, requires_grad=True)\n",
    "    opt = torch.optim.LBFGS([g])\n",
    "    def ll(g):\n",
    "        return torch.sum(freqs * g) - torch.sum(torch.logsumexp(g, 1)) - l2/2 * torch.norm(g)**2\n",
    "    for t in range(n_iter):\n",
    "        opt.zero_grad()\n",
    "        loss = -ll(g)\n",
    "        loss.backward()\n",
    "        opt.step(lambda: -ll(g))\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    N = freqs.shape[0]\n",
    "    g_pwm  = g.exp() / g.exp().sum(dim=1).reshape(N,1) + l2 * g\n",
    "    \n",
    "    fields = g.detach().numpy()\n",
    "    pwmi = g_pwm.detach().numpy()\n",
    "    \n",
    "    return (fields, pwmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train and test (by the AUC of discrimination of specific vs background receptors) the diffRBM TCR specificity models and compare them to other RBM and PWM-based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## These are combinations of options: whether to include VJ segments, what background dataset to use\n",
    "combinations = [[1,'emerson_training_test'], [0,'emerson_training_test'], [1,'dean_training_test']]\n",
    "\n",
    "for combo in combinations:\n",
    "    \n",
    "    makeVJ = combo[0] ## just to decide if to include V and J or not ##\n",
    "\n",
    "    if makeVJ:\n",
    "        strVJ = 'withVJ'\n",
    "    else:\n",
    "        strVJ = 'withoutVJ'\n",
    "        \n",
    "    replBB = 0\n",
    "    add_vj = strVJ\n",
    "\n",
    "    list_pepa=['YLQPRTFLL','NLVPMVATV','GLCTLVAML','GILGFVFTL']\n",
    "    list_pep=list_pepa\n",
    "    \n",
    "    dataset_back = combo[1]\n",
    "    if dataset_back == 'emerson_training_test':\n",
    "        add_str=''\n",
    "    else:\n",
    "        add_str='D'\n",
    "\n",
    "    for pep in list_pep:\n",
    "\n",
    "        SA=20\n",
    "\n",
    "        dataset = 'diffRBM_'+ pep ## This is the name of the folder with the model; if does not exist I create it \n",
    "        name_folder = rootf + '/TCR_specificity_model/' + dataset # Name folder reflects what peptide-specific dataset one is considering #\n",
    "       \n",
    "        if os.path.exists(name_folder) is False:\n",
    "            os.mkdir(name_folder)\n",
    "\n",
    "        name_mf = '/models'\n",
    "        if os.path.exists(name_folder + name_mf + '/') is False:\n",
    "            os.mkdir(name_folder + name_mf + '/')\n",
    "\n",
    "        name_mff = '/models/indices'\n",
    "        if os.path.exists(name_folder + name_mff + '/') is False:\n",
    "            os.mkdir(name_folder + name_mff + '/')\n",
    "\n",
    "        # load JV2num dicts - see comment below\n",
    "        t_df = pd.read_csv(name_folder + '/J2num_dict_train_train.csv')\n",
    "        J2num_dict = dict(zip(t_df['J_gene'], t_df['RBM_VU_id']))\n",
    "        t_df = pd.read_csv(name_folder + '/V2num_dict_train_train.csv')\n",
    "        V2num_dict = dict(zip(t_df['V_gene'], t_df['RBM_VU_id']))\n",
    "\n",
    "        vdgdb_df = pd.read_csv(rootf + '/TCR_specificity_model/diffRBM_' + pep + '/VDJdb_' + pep + '_WithAligned20.csv')\n",
    "        train_data = vdgdb_df.drop_duplicates().reset_index(drop=True)\n",
    "        # do num2seq\n",
    "        t_trainseq = train_data[\"ali_seq\"].to_list()\n",
    "        trainseq_2num = np.array(Proteins_utils.seq2num(t_trainseq), dtype=np.int16)\n",
    "        # add to gen_seqs2num two integers for each row, obtained from V and J\n",
    "        Vlist = train_data[\"TRBV_gene\"].to_list()\n",
    "        Jlist = train_data[\"TRBJ_gene\"].to_list()\n",
    "\n",
    "        train_2num_withVJ = add_VJ_info_2num(trainseq_2num, Vlist, Jlist, V2num_dict, J2num_dict)\n",
    "\n",
    "        if makeVJ:\n",
    "            train_dataI = np.copy(train_2num_withVJ)\n",
    "        else:\n",
    "            train_dataI = np.copy(train_2num_withVJ[:,:-2])\n",
    "\n",
    "        Mb=1000000\n",
    "        filename_cdr3 = rootf + '/TCR_specificity_model/' + dataset_back + '/train_data_0_aligned_20.txt' \n",
    "        filename_cdr3raw = rootf + '/TCR_specificity_model/' + dataset_back + '/train_data_0.txt' \n",
    "        train_seq0=[]\n",
    "        with open(filename_cdr3) as f:\n",
    "            for line in f:\n",
    "                linesplit = line.strip().split('\\n')\n",
    "                train_seq0.append(linesplit[0])\n",
    "        train_dataB_num = convert_number(train_seq0)                       \n",
    "        if makeVJ:\n",
    "            ffraw = pd.read_csv(filename_cdr3raw,sep='\\t',header=None)\n",
    "            VlistB = list(np.array(ffraw)[:,1])\n",
    "            JlistB = list(np.array(ffraw)[:,2])\n",
    "            train_2num_withVJ_B = add_VJ_info_2num(train_dataB_num, VlistB, JlistB, V2num_dict, J2num_dict)\n",
    "            train_dataBI = train_2num_withVJ_B[:Mb]\n",
    "        else:\n",
    "            train_dataBI = train_dataB_num[:Mb]\n",
    "\n",
    "        seqs_temp = list(train_dataI)\n",
    "            \n",
    "        Mbv=10000\n",
    "        filename_cdr3 = rootf + '/TCR_specificity_model/'+dataset_back+'/train_data_1_aligned_20.txt' \n",
    "        filename_cdr3raw = rootf + '/TCR_specificity_model/'+dataset_back +'/train_data_1.txt' \n",
    "        inds_non_overlap = np.loadtxt(rootf + '/TCR_specificity_model/' + dataset_back + '/1_inds_nonoverlap_0.txt').astype(np.int16)\n",
    "        train_seq0=[]\n",
    "        with open(filename_cdr3) as f:\n",
    "            for line in f:\n",
    "                linesplit = line.strip().split('\\n')\n",
    "                train_seq0.append(linesplit[0])\n",
    "        train_dataB_num = convert_number(train_seq0)                       \n",
    "        if makeVJ:\n",
    "            ffraw = pd.read_csv(filename_cdr3raw,sep='\\t',header=None)\n",
    "            VlistB = list(np.array(ffraw)[:,1])\n",
    "            JlistB = list(np.array(ffraw)[:,2])\n",
    "            train_2num_withVJ_B = add_VJ_info_2num(train_dataB_num, VlistB, JlistB, V2num_dict, J2num_dict)\n",
    "            train_dataBIv = train_2num_withVJ_B[inds_non_overlap[:Mbv]]\n",
    "        else:\n",
    "            train_dataBIv = train_dataB_num[inds_non_overlap[:Mbv]]\n",
    "\n",
    "        train_dataBIv0 = np.copy(train_dataBIv)\n",
    "        \n",
    "        first_run = 0\n",
    "        makefig=0\n",
    "        maketrainingpwm=0\n",
    "        make_pos=1\n",
    "        maketrainingP=0\n",
    "        maketraining=0\n",
    "        maketrainingB=0\n",
    "\n",
    "        print_table = 0\n",
    "        makeRW=0\n",
    "        maketrainingN=0\n",
    "        maketrainingpwmN=0\n",
    "        list_negs=['control']\n",
    "\n",
    "        for name_neg in list_negs:\n",
    "           \n",
    "            if makeVJ:\n",
    "                n_cv = np.max(np.unique(train_dataBI[:,-2])) + 1\n",
    "            else:\n",
    "                n_cv=21\n",
    "\n",
    "            seqs_tempN = list(train_dataBIv)\n",
    "            \n",
    "            listreg = [0.01]\n",
    "            listhu = [20] ## lists of hidden units in top RBM\n",
    "            listregB = [0.001] ## lists of weight regularization in top RBM\n",
    "            listhuB = [100]## lists of hidden units in top RBM\n",
    "\n",
    "            ## Various parameters ##\n",
    "            th = 0.15 ## similarity threshold if you set the reweighting\n",
    "            vv = 1\n",
    "            what_l12='Standard'\n",
    "            what_l2='Standard'\n",
    "            \n",
    "            ## RBM parameters ##\n",
    "            ZF = False ## control the introduction of fields ##\n",
    "            BN = True ## control batch_size ##\n",
    "\n",
    "            visible = 'Potts' # Nature of visible units potential. Here, Potts states.\n",
    "            hidden = 'dReLU' # Nature of hidden units potential. Here, dReLU potential.\n",
    "            \n",
    "            seed = 0\n",
    "            decay_after = 0.5 # Decay learning rate after 50% of iterations (default: 0.5). Value for RBM shown in paper: 0.5\n",
    "            N_MC = 15\n",
    "\n",
    "            RR=50\n",
    "            npw=250\n",
    "\n",
    "            ## percentage to use in the training dataset ##\n",
    "            B = 80 ## percentage for positives ##\n",
    "            Bm = 80\n",
    "            BB = 100 ## percentage for background ##\n",
    "\n",
    "            if not(first_run) and maketraining:\n",
    "                print(\"ATTENTION YOU ARE RETRAINING THE MODELS\")\n",
    "            if first_run and not(maketraining):\n",
    "                print(\"ATTENTION YOU ARE NOT TRAINING THE MODELS\")\n",
    "\n",
    "            log_file = name_folder + name_mf + '/Log.txt'\n",
    "            print('Start training for peptide ' + pep + '\\n')\n",
    "            f = open(log_file,'a+')\n",
    "            f.write('Start training for peptide ' + pep + '\\n')\n",
    "            f.close()\n",
    "\n",
    "            for lib in listreg:\n",
    "                for hh in listhu:\n",
    "                    for hhB in listhuB:\n",
    "                        for libB in listregB:\n",
    "\n",
    "                            ## DIFFRBM and RBM ##\n",
    "                            ## disinguish positives from negatives and vice-versa ##\n",
    "                            list_auc_diff=[] ## diffRBM\n",
    "                            list_auc_top=[] ## top part of diffRBM\n",
    "                            list_auc_diffN=[] ## diffRBM (negatives) \n",
    "                            list_auc_topN=[] ## top part of diffRBM (negatives)\n",
    "                            list_auc_difftops=[] ## difference of tops\n",
    "                            list_auc_diffdiff=[] ## difference of diff (same as top)\n",
    "                            list_auc_rbm=[] # normal RBM\n",
    "                            list_auc_diffrbm=[] # difference of normal RBMs\n",
    "                            \n",
    "                            # DIFFRBM with Linear top #\n",
    "                            list_auc_diff_lin=[]\n",
    "                            list_auc_diff_linN = []\n",
    "                            list_auc_top_lin = []\n",
    "                            list_auc_top_linN = []\n",
    "                            list_auc_difftops_lin=[]\n",
    "\n",
    "                            ## Alternative approaches: independent-site models ## \n",
    "                            list_auc_pwm=[]\n",
    "                            list_auc_diffpwm=[]\n",
    "\n",
    "                            ## Alternative approaches: differential independent-site models ## \n",
    "                            list_auc_top_dpwm_pos=[]\n",
    "                            list_auc_diff_dpwm_pos=[]\n",
    "                            list_auc_top_dpwm_neg=[]\n",
    "                            list_auc_diff_dpwm_neg=[]\n",
    "                            list_auc_top_dpwm_diff=[]\n",
    "\n",
    "                            ## discrimination performance of the background\n",
    "                            list_auc_backrbm=[]\n",
    "                            list_auc_backpwm=[]\n",
    "\n",
    "                            for repl in range(RR):\n",
    "    \n",
    "                                ## Reshuffle data before dividing - I also save reshuffled indices ##\n",
    "\n",
    "                                path_o = name_folder + name_mff + '/index_permutation_repl' + str(repl) + '.txt'\n",
    "                        \n",
    "                                if first_run:\n",
    "                                    full_int = list(np.arange(int(len(seqs_temp)*1)))\n",
    "                                    full_intR = random.sample(full_int, int(1*(len(seqs_temp))))\n",
    "                                    np.savetxt(path_o, np.array(full_intR).astype(int), fmt=\"%i\")\n",
    "\n",
    "                                full_intR = list((np.loadtxt(path_o)).astype(np.int))\n",
    "                                full_intRp = list((np.loadtxt(path_o)).astype(np.int))\n",
    "                                data = np.array([seqs_temp[t] for t in full_intR])\n",
    "\n",
    "                                path_o = name_folder + name_mff + '/index_permutationN_repl' + str(repl) + '.txt'\n",
    "\n",
    "                                if first_run:\n",
    "                                    full_int = list(np.arange(int(len(seqs_tempN)*1)))\n",
    "                                    full_intR = random.sample(full_int, int(1*(len(seqs_tempN))))\n",
    "                                    np.savetxt(path_o, np.array(full_intR).astype(int), fmt=\"%i\")\n",
    "\n",
    "                                full_intR = list((np.loadtxt(path_o)).astype(np.int))\n",
    "\n",
    "                                full_intRn = list((np.loadtxt(path_o)).astype(np.int))\n",
    "                                train_dataBIv = np.array([seqs_tempN[t] for t in full_intR])\n",
    "\n",
    "                                train_data = data[:int(B*len(data)/100)]\n",
    "                                val_data = data[int(B*len(data)/100):]\n",
    "                                #train_data_all.append(data)\n",
    "                                \n",
    "                                if makeRW:\n",
    "                                    reweight = utilities_diffrbm.compute_MSA_weights(train_data, threshold = th)\n",
    "                                Mt = len(train_data)\n",
    "\n",
    "                                train_dataB = train_dataBI[:int(BB*len(train_dataBI)/100)]\n",
    "                                val_dataB = train_dataBIv[:len(val_data)]\n",
    "                                \n",
    "                                val_dataN = np.copy(val_dataB)\n",
    "                                MtN = len(train_dataB)\n",
    "\n",
    "                                Mb = len(train_dataB)\n",
    "\n",
    "                                if makeRW:\n",
    "                                    reweightB = utilities_diffrbm.compute_MSA_weights(train_dataB, threshold = th)\n",
    "\n",
    "                                f = open(log_file,'a+')\n",
    "                                f.write('Size background ' + str(len(train_dataB)) + '\\n')\n",
    "                                f.close\n",
    "                                \n",
    "                                if makefig:\n",
    "                                    name_w = name_folder + '/presentation/model' + mod + '_weights.png'\n",
    "                                    weB = RBM_back.weights\n",
    "                                    interesting_features = list(np.arange(n_hB))\n",
    "                                    fig = sequence_logo.Sequence_logo_multiple(weB[interesting_features], figsize=(5.5,1.8), ylabel = 'weights ',  ticks_every=5, ticks_labels_size=s2-2) \n",
    "                                    \n",
    "\n",
    "                                if what_l2=='Standard':\n",
    "                                    reg_fields_diffpos = 1/Mt\n",
    "                                    reg_fields_diffneg = 1/MtN\n",
    "                                else:\n",
    "                                    reg_fields_diffpos = (abs(Mt - Mb) + 1)/Mt\n",
    "                                    reg_fields_diffneg = (abs(MtN - Mb) + 1)/MtN\n",
    "\n",
    "                                if what_l12=='Standard':\n",
    "                                    reg_weights_diffpos = lib\n",
    "                                    reg_weights_diffneg = lib\n",
    "                                else:\n",
    "                                    reg_weights_diffpos = Mb/Mt*lib\n",
    "                                    reg_weights_diffneg = Mb/MtN*lib\n",
    "\n",
    "                                n_v = train_dataB.shape[1] # Number of visible units = # sites in alignment.\n",
    "\n",
    "                                l2f = 1/Mb\n",
    "\n",
    "                                n_hB = hhB\n",
    "                                l1bB = libB\n",
    "                                decay_after = 0.5\n",
    "                                N_MC = 10\n",
    "\n",
    "                                batch_size = 2000\n",
    "                                n_iter = 40\n",
    "                                replB = replBB\n",
    "\n",
    "                                name_back = 'backRBM-100hu-lowreg-'+ strVJ +'-train_train_WithoutDuplicates_repl'+str(replB)+'_' + str(Mb) + add_str \n",
    "                                nameB = rootf + '/TCR_specificity_model/' + name_back +'.data'\n",
    "\n",
    "                                if maketrainingB:\n",
    "                                    RBM_back = rbm.RBM(n_h = hhB, n_v = len(train_dataB[0]),n_cv= n_cv, visible='Potts', hidden='dReLU',random_state = seed, zero_field = False)\n",
    "                                    if maketrainingB:\n",
    "                                        RBM_back.fit(train_dataB, weights = None, batch_size = batch_size, n_iter = n_iter, l1b = libB, l2_fields = l2f, N_MC = N_MC, decay_after = decay_after, verbose = 1, shuffle_data=False, CD=False)\n",
    "                                   \n",
    "                                        RBM_utils.saveRBM(nameB, RBM_back)\n",
    "\n",
    "                                RBM_back =  RBM_utils.loadRBM(nameB)\n",
    "                                \n",
    "                                l2f = reg_fields_diffpos\n",
    "                               \n",
    "                                learning_rate = None # default behaviour\n",
    "                                decay_after = 0.5\n",
    "                                N_MC = 10\n",
    "                               \n",
    "                                if pep == 'YLQPRTFLL':\n",
    "                                    bb = 16\n",
    "                                else:\n",
    "                                    bb = 100\n",
    "                                if pep == 'NLVPMVATV': \n",
    "                                    bb = 200\n",
    "\n",
    "                                nni = int(2e4) // (train_data.shape[0] // bb)\n",
    "\n",
    "                                batch_size = bb\n",
    "                                n_iter = nni\n",
    "                                \n",
    "                                n_v = train_data.shape[1] # Number of visible units = # sites in alignment.\n",
    "                                name_top = name_folder + name_mf +  '/topmodel_imm_repl' + str(repl) + add_str \n",
    "                                n_h_top = hh\n",
    "                                out_par0 = '_RW' + str(makeRW) + '_TR' + str(B) + add_vj\n",
    "                                out_par = '_nh' + str(n_h_top) + '_l12' + str(lib) + '_ZF' + str(ZF) + out_par0\n",
    "\n",
    "                                RBMpost = rbm.RBM(n_h = RBM_back.n_h + n_h_top, n_v = RBM_back.n_v, n_cv= RBM_back.n_cv, visible='Potts', hidden=hidden, zero_field=ZF)\n",
    "                                dRBM = diffrbm.DiffRBM(RBM_back, RBMpost)\n",
    "                                dRBM.update_post_from_back(vlayer=True, hlayer=True)\n",
    "                                \n",
    "                                if maketraining:\n",
    "                                    if makeRW:\n",
    "                                        dRBM.fit_top(train_data, weights=reweight, n_iter=n_iter, batch_size=batch_size, l2_fields = l2f, l1b=reg_weights_diffpos, N_MC=N_MC, decay_after=decay_after, verbose=vv, vverbose=vv, batch_norm=BN)\n",
    "                                    else:\n",
    "                                        dRBM.fit_top(train_data, weights=None, n_iter=n_iter, batch_size=batch_size, l2_fields = l2f, l1b=reg_weights_diffpos, N_MC=N_MC, decay_after=decay_after, verbose=vv, vverbose=vv, batch_norm=BN)\n",
    "                                    RBM_utils.saveRBM(name_top + out_par + '.data', dRBM)\n",
    "                                \n",
    "                                dRBM =  RBM_utils.loadRBM(name_top + out_par + '.data')\n",
    "                                llp = -dRBM.top_rbm().free_energy(val_data.astype(np.int16))\n",
    "                                lln = -dRBM.top_rbm().free_energy(val_dataN.astype(np.int16))\n",
    "\n",
    "                                labels = np.hstack((np.ones((len(val_data))), np.zeros((len(val_dataN))) )) \n",
    "                                scores = np.hstack((llp, lln))\n",
    "                                fpr, tpr, thresholds = metrics.roc_curve(labels, scores)\n",
    "                                nn = metrics.auc(fpr, tpr)\n",
    "                                list_auc_top.append(nn)\n",
    "\n",
    "                                llp = -RBM_back.free_energy(val_data.astype(np.int16))\n",
    "                                lln = -RBM_back.free_energy(val_dataN.astype(np.int16))\n",
    "\n",
    "                                labels = np.hstack((np.ones((len(val_data))), np.zeros((len(val_dataN))) )) \n",
    "                                scores = np.hstack((llp, lln))\n",
    "                                fpr, tpr, thresholds = metrics.roc_curve(labels, scores)\n",
    "                                nn = metrics.auc(fpr, tpr)\n",
    "                                list_auc_backrbm.append(nn)\n",
    "                                \n",
    "                                llp = -dRBM.RBMpost.free_energy(val_data.astype(np.int16)) \n",
    "                                lln = -dRBM.RBMpost.free_energy(val_dataN.astype(np.int16)) \n",
    "\n",
    "                                labels = np.hstack((np.ones((len(val_data))), np.zeros((len(val_dataN))) )) \n",
    "                                scores = np.hstack((llp, lln))\n",
    "                                fpr, tpr, thresholds = metrics.roc_curve(labels, scores)\n",
    "                                nn = metrics.auc(fpr, tpr)\n",
    "                                list_auc_diff.append(nn)\n",
    "\n",
    "                                name_rbm = name_folder + name_mf + '/normmodel_imm_repl' + str(repl) + add_str\n",
    "                                \n",
    "                                l2f = 1/Mt\n",
    "                                n_h = hh\n",
    "\n",
    "                                batch_size = bb\n",
    "                                n_iter = nni\n",
    "                                if make_pos:\n",
    "                                    RBM = rbm.RBM(visible = visible, hidden = hidden, n_v = n_v, n_h = n_h, n_cv = n_cv, random_state = seed, zero_field=ZF)\n",
    "                                    if maketrainingP:\n",
    "                                        if makeRW:\n",
    "                                            RBM.fit(train_data, weights=reweight, batch_size=batch_size, l2_fields = l2f, n_iter=n_iter, l1b=lib, N_MC=N_MC, decay_after=decay_after, verbose=vv, vverbose=vv)\n",
    "                                        else:\n",
    "                                            RBM.fit(train_data, weights=None, batch_size=batch_size, l2_fields = l2f, n_iter=n_iter, l1b=lib, N_MC=N_MC, decay_after=decay_after, verbose=vv, vverbose=vv)\n",
    "                                        RBM_utils.saveRBM(name_rbm + out_par + '.data', RBM)\n",
    "                                    RBM =  RBM_utils.loadRBM(name_rbm + out_par + '.data')\n",
    "\n",
    "                                name_top = name_folder + name_mf + '/topmodellin_imm_repl' + str(repl)\n",
    "                                n_h_top = hh\n",
    "\n",
    "                                l2f = reg_fields_diffpos\n",
    "\n",
    "                                batch_size = bb\n",
    "                                n_iter = nni\n",
    "\n",
    "                                RBMpost_lin = rbm.RBM(n_h = RBM_back.n_h + n_h_top, n_v = RBM_back.n_v, n_cv= RBM_back.n_cv, visible=visible, hidden=hidden, zero_field=ZF)\n",
    "                                dRBM_lin = diffrbm.DiffRBM(RBM_back, RBMpost_lin)\n",
    "                                dRBM_lin.update_post_from_back(vlayer=True, hlayer=True)\n",
    "\n",
    "                                if maketraining:\n",
    "                                    if makeRW:\n",
    "                                        dRBM_lin.fit_top(train_data, weights=reweight, n_iter=n_iter, batch_size=batch_size, l2_fields = l2f, l1b=reg_weights_diffpos, N_MC=N_MC, decay_after=decay_after, verbose=vv, vverbose=vv, batch_norm=BN, callback = produce_callback_weights(dRBM_lin))\n",
    "                                    else:\n",
    "                                        dRBM_lin.fit_top(train_data, weights=None, n_iter=n_iter, batch_size=batch_size, l2_fields = l2f, l1b=reg_weights_diffpos, N_MC=N_MC, decay_after=decay_after, verbose=vv, vverbose=vv, batch_norm=BN, callback = produce_callback_weights(dRBM_lin))\n",
    "                                    RBM_utils.saveRBM(name_top + out_par + '.data', dRBM_lin)\n",
    "                                dRBM_lin =  RBM_utils.loadRBM(name_top + out_par + '.data')\n",
    "\n",
    "        \n",
    "                                if make_pos:\n",
    "                                    llp = -RBM.free_energy(val_data.astype(np.int16))\n",
    "                                    lln = -RBM.free_energy(val_dataN.astype(np.int16))\n",
    "\n",
    "                                    labels = np.hstack((np.ones((len(val_data))), np.zeros((len(val_dataN))) )) \n",
    "                                    scores = np.hstack((llp, lln))\n",
    "                                    fpr, tpr, thresholds = metrics.roc_curve(labels, scores)\n",
    "                                    nn = metrics.auc(fpr, tpr)\n",
    "                                    list_auc_rbm.append(nn)\n",
    "\n",
    "                                llp = -dRBM_lin.RBMpost.free_energy(val_data.astype(np.int16))\n",
    "                                lln = -dRBM_lin.RBMpost.free_energy(val_dataN.astype(np.int16))\n",
    "\n",
    "                                labels = np.hstack((np.ones((len(val_data))), np.zeros((len(val_dataN))) )) \n",
    "                                scores = np.hstack((llp, lln))\n",
    "                                fpr, tpr, thresholds = metrics.roc_curve(labels, scores)\n",
    "                                nn = metrics.auc(fpr, tpr)\n",
    "                                list_auc_diff_lin.append(nn)\n",
    "\n",
    "                                llp = -dRBM_lin.top_rbm().free_energy(val_data.astype(np.int16))\n",
    "                                lln = -dRBM_lin.top_rbm().free_energy(val_dataN.astype(np.int16))   \n",
    "\n",
    "                                labels = np.hstack((np.ones((len(val_data))), np.zeros((len(val_dataN))) )) \n",
    "                                scores = np.hstack((llp, lln))\n",
    "                                fpr, tpr, thresholds = metrics.roc_curve(labels, scores)\n",
    "                                nn = metrics.auc(fpr, tpr)\n",
    "                                list_auc_top_lin.append(nn)\n",
    "\n",
    "                                print('I start to compare to a differential PWM')\n",
    "\n",
    "                                if maketrainingpwm:\n",
    "                                    if makeRW:\n",
    "                                        pre_fields = utilities.average(train_dataB, c=n_cv, weights=reweightB)\n",
    "                                    else:\n",
    "                                        pre_fields = utilities.average(train_dataB, c=n_cv)\n",
    "\n",
    "                                    fields_back, pwmB = regularized_pwm_torch(torch.from_numpy(pre_fields), 1/(Mb), n_iter= npw)\n",
    "\n",
    "                                \n",
    "                                    if makeRW:\n",
    "                                        pre_fields = utilities.average(train_data, c=n_cv, weights=reweight)\n",
    "                                    else:\n",
    "                                        pre_fields = utilities.average(train_data, c=n_cv)\n",
    "\n",
    "                                    fields_diff_pos, pwm_diff_pos = regularized_pwm_torch(torch.from_numpy(pre_fields), reg_fields_diffpos, n_iter= npw)\n",
    "\n",
    "                                    np.savetxt(name_folder + name_mf + '/fields_pos_repl' + str(repl) + add_str + out_par0 +'.txt', fields_diff_pos)\n",
    "                                    np.savetxt(name_folder + name_mf + '/fields_back' + add_str + out_par0 + '.txt', fields_back)\n",
    "                                else:\n",
    "                                    fields_diff_pos = np.loadtxt(name_folder + name_mf + '/fields_pos_repl' + str(repl) + add_str+ out_par0 +'.txt')\n",
    "                                    fields_back = np.loadtxt(name_folder + name_mf + '/fields_back' + add_str+ out_par0 +'.txt')       \n",
    "\n",
    "                                fields_top_pos = fields_diff_pos - fields_back\n",
    "                                \n",
    "                                pos_v_2num = np.copy(val_data)\n",
    "                                neg_v_2num = np.copy(val_dataN)\n",
    "                                # compute AUCs - top_dpwm_pos (trained on positives) - I set logZ=1 since it is useless here\n",
    "                                scores_positives_val = loglikelihood_indip_model(fields_top_pos, 1, pos_v_2num)\n",
    "                                scores_negatives_val = loglikelihood_indip_model(fields_top_pos, 1, neg_v_2num)\n",
    "                                labels = np.hstack((np.zeros((len(scores_negatives_val))), np.ones((len(scores_positives_val))))) \n",
    "                                scores = np.hstack((scores_negatives_val, scores_positives_val))\n",
    "                                fpr, tpr, thresholds = metrics.roc_curve(labels, scores)\n",
    "                                list_auc_top_dpwm_pos.append(metrics.auc(fpr, tpr))\n",
    "\n",
    "                                # compute AUCs - diff_dpwm_pos (trained on positives)\n",
    "                                scores_positives_val = loglikelihood_indip_model(fields_diff_pos, 1, pos_v_2num)\n",
    "                                scores_negatives_val = loglikelihood_indip_model(fields_diff_pos, 1, neg_v_2num)\n",
    "                                labels = np.hstack((np.zeros((len(scores_negatives_val))), np.ones((len(scores_positives_val))))) \n",
    "                                scores = np.hstack((scores_negatives_val, scores_positives_val))\n",
    "                                fpr, tpr, thresholds = metrics.roc_curve(labels, scores)    \n",
    "                                list_auc_diff_dpwm_pos.append(metrics.auc(fpr, tpr))\n",
    "\n",
    "                                scores_positives_val = loglikelihood_indip_model(fields_back, 1, pos_v_2num)\n",
    "                                scores_negatives_val = loglikelihood_indip_model(fields_back, 1, neg_v_2num)\n",
    "                                labels = np.hstack((np.zeros((len(scores_negatives_val))), np.ones((len(scores_positives_val))))) \n",
    "                                scores = np.hstack((scores_negatives_val, scores_positives_val))\n",
    "                                fpr, tpr, thresholds = metrics.roc_curve(labels, scores)    \n",
    "                                list_auc_backpwm.append(metrics.auc(fpr, tpr))\n",
    "\n",
    "                    ## Final predictions ##\n",
    "                    list_aucs1 = [list_auc_top,list_auc_diff, list_auc_top_lin, list_auc_diff_lin, list_auc_top_dpwm_pos,list_auc_diff_dpwm_pos, list_auc_rbm, list_auc_backrbm, list_auc_backpwm]\n",
    "                    list_aucs_names1 = ['top RBM','diffRBM', 'top RBM (lin)','diffRBM (lin)','top PWM', 'diffPWM', 'Normal RBM', 'RBMback', 'PWMback']\n",
    "\n",
    "                    fig,ax=plt.subplots()\n",
    "                    fig.set_figheight(5)\n",
    "                    fig.set_figwidth(15)\n",
    "\n",
    "                    meth = list_aucs_names1\n",
    "                    meth_val = [np.mean(ll) for ll in list_aucs1]\n",
    "                    error = [np.std(ll) for ll in list_aucs1]\n",
    "\n",
    "                    x_pos = np.arange(0,2*len(meth_val),2)\n",
    "                \n",
    "                    colors3 = list(np.repeat(['Maroon'],len(meth)))\n",
    "                    s2 = 16\n",
    "                    sc = 2\n",
    "\n",
    "                    bars = ax.bar(x_pos, meth_val, yerr=error, alpha=1, edgecolor='k', align = 'center', capsize=sc, color = colors3)\n",
    "\n",
    "                    ax.set_xticks(x_pos)\n",
    "                    ax.set_ylabel('AUC', fontsize = s2)\n",
    "                    ax.tick_params(axis='y', which='major', labelsize = s2)\n",
    "                    ax.set_xticklabels(meth, rotation = 30, fontsize  = s2-3, ha='right', rotation_mode = 'anchor')\n",
    "                    ax.set_title('Performance at discriminating pos-neg for peptide ' + pep + str(np.mean(list_auc_backrbm)), fontsize = s2)\n",
    "                    ax.set_ylim([0,1]);\n",
    "                    \n",
    "                    ## print final table ##\n",
    "                    if print_table:\n",
    "                        list_aucs = list_aucs1\n",
    "                        list_aucs_names = list_aucs_names1 \n",
    "                        dataf = {list_aucs_names[k]:list_aucs[k] for k in range(len(list_aucs))}\n",
    "                        df = pd.DataFrame(dataf, columns = list_aucs_names)\n",
    "                        df.to_csv(name_folder + '/'+ add_str + 'final_aucs' + add_vj  + '.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate the diffRBM units' single-site factors and test their performance at predicting contacts between the CDR3beta and the peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeVJ=0 ## for contacts, we need only the amino-acid part \n",
    "\n",
    "if makeVJ:\n",
    "    strVJ = 'withVJ'\n",
    "else:\n",
    "    strVJ = 'withoutVJ'\n",
    "\n",
    "print_table = 0\n",
    "\n",
    "listP = [['YLQPRTFLL','NLVPMVATV','GLCTLVAML','GILGFVFTL'], ['YLQPRTFLL'], ['NLVPMVATV'], ['GLCTLVAML'],['GILGFVFTL']]\n",
    "\n",
    "Mb = 1000000\n",
    "l2f = 1/Mb\n",
    "for RP in [1,0]:\n",
    "    for Pi in range(len(listP)):\n",
    "        list_pep=listP[Pi]\n",
    "        list_ppv_pwm=[]\n",
    "        list_ppv_rbm=[]\n",
    "        npw=250\n",
    "\n",
    "        ## min dist at which I see at least 1 contact per peptide -> 3.5\n",
    "        for TH in [3.8,4,4.5,5]:\n",
    "            name_folderF = rootf + '/Immunogenicity_model/PDB_structures/'\n",
    "            perfs=[]\n",
    "\n",
    "            range_len = [8,9,10,11]\n",
    "\n",
    "            range_len_target  = [9]\n",
    "\n",
    "            ## parameters for the alignment ##\n",
    "            SA = 9\n",
    "            SAmin = 8\n",
    "            SAmax = 11\n",
    "\n",
    "            makeextractionB = 0\n",
    "            makeRW = 0\n",
    "            vv = 0\n",
    "\n",
    "            ## percentage to use in the training dataset ##\n",
    "            B = 100 ## percentage for positives ##\n",
    "            Bm = 100 ## percentage for negatives ##\n",
    "            BB = 100 ## percentage for background ##\n",
    "\n",
    "            ## Background model parameters ##\n",
    "            l1bB = 0.001\n",
    "            n_hB = 10\n",
    "            listregB = [l1bB] ## lists of weight regularization in top RBM\n",
    "            listhuB = [n_hB] \n",
    "\n",
    "            ## parameters of diffRBM ##\n",
    "            listreg = [0.01] ## lists of weight regularization in top RBM\n",
    "            listhu = [10] ## lists of hidden units in top RBM\n",
    "            n_min = 300 ## maximal fields regularization\n",
    "\n",
    "            ## RBM parameters ##\n",
    "            ZF = False ## control the introduction of fields ##\n",
    "            BN = True ## control batch_norm ##\n",
    "\n",
    "            visible = 'Potts' # Nature of visible units potential. Here, Potts states.\n",
    "            hidden = 'dReLU' # Nature of hidden units potential. Here, dReLU potential.\n",
    "            seed = 0\n",
    "            decay_after = 0.5 # Decay learning rate after 50% of iterations (default: 0.5). Value for RBM shown in paper: 0.5\n",
    "            N_MC = 15\n",
    "            fac = 1\n",
    "\n",
    "            maketrainingB = 0 ## retrain the background data ##\n",
    "            maketraining = 0 ## train diffRBM ##\n",
    "            first_run = 0\n",
    "            makefig = 0\n",
    "            make_neg = 0\n",
    "            maketrainingN = 0\n",
    "            what_l2 = 'Standard'\n",
    "            reweight_ppv = RP ## wheher one should re-weight same peptide entries \n",
    "            th = 0.1 ## similarity threshold if you set the reweighting: 0.1 (only same); 0.2 (1 mut away)\n",
    "            if reweight_ppv==0:\n",
    "                th=0\n",
    "            if len(list_pep)>1:\n",
    "                pepN='All'\n",
    "            else:\n",
    "                pepN=list_pep[0]\n",
    "            make_unique_cont = 1 ## only unique seqs + set of contact positions\n",
    "            make_unique = 0  ## only unique seqs\n",
    "\n",
    "            l1=[]\n",
    "            l1lin=[]\n",
    "            l1b=[]\n",
    "            l12=[]\n",
    "            l1b1=[]\n",
    "            l1b2=[]\n",
    "            posR=[]\n",
    "            posF=[]\n",
    "            posB=[]\n",
    "            posB1=[]\n",
    "            posB2=[]\n",
    "            l2=[]\n",
    "            posRlin=[]\n",
    "            posP=[]\n",
    "            ligands=[]\n",
    "            true_contacts_hla=[]\n",
    "            rws_hla=[]\n",
    "\n",
    "            for p0 in range(len(list_pep)):\n",
    "\n",
    "                lik_pos=[]\n",
    "                lik_neg=[]\n",
    "                lik_back=[]\n",
    "                lik_pos_pwm=[]\n",
    "                lik_neg_pwm=[]\n",
    "                lik_back_pwm=[]\n",
    "\n",
    "                count=0\n",
    "                list_pos=[]\n",
    "\n",
    "                pep = list_pep[p0]\n",
    "\n",
    "\n",
    "                file = pd.read_csv(name_folderF + '/contacts_ang' + str(TH) + '_fin.tsv', sep='\\t')\n",
    "                filea02 = file[file['Ligand'] == pep]\n",
    "\n",
    "\n",
    "                ## CONTACT analysis: frequency of contact residues in structural data #                                   \n",
    "                seqs0f = list(filea02['CDR3 seq'])\n",
    "                cont0 = list(filea02['Pep contact positions (CDR3beta)'].values)\n",
    "                seqs0 = list(filea02['CDR3 seq al'].values)\n",
    "\n",
    "                # load peptide to be excluded in the training set\n",
    "                seq_to_be_excluded = np.loadtxt(rootf + '/TCR_specificity_model/exclude_'+pep+'.txt', dtype=str)\n",
    "                # prepare train_2num_withVJ\n",
    "                vdgdb_df = pd.read_csv(rootf + '/TCR_specificity_model/diffRBM_'+pep+'/VDJdb_'+pep+'_WithAligned20.csv')\n",
    "                vdgdb_df = vdgdb_df.drop_duplicates().reset_index(drop=True)\n",
    "                train_data = vdgdb_df[~vdgdb_df[\"CDR3_beta\"].isin(seq_to_be_excluded)]\n",
    "\n",
    "                # do num2seq\n",
    "                t_trainseq = train_data[\"ali_seq\"].to_list()\n",
    "                trainseq_2num = np.array(Proteins_utils.seq2num(t_trainseq), dtype=np.int16)\n",
    "                # add to gen_seqs2num two integers for each row, obtained from V and J\n",
    "                Vlist = train_data[\"TRBV_gene\"].to_list()\n",
    "                Jlist = train_data[\"TRBJ_gene\"].to_list()\n",
    "\n",
    "                t_df = pd.read_csv(rootf + '/TCR_specificity_model/diffRBM_'+pep+'/J2num_dict_train_train.csv')\n",
    "                J2num_dict = dict(zip(t_df['J_gene'], t_df['RBM_VU_id']))\n",
    "                t_df = pd.read_csv(rootf + '/TCR_specificity_model/diffRBM_'+pep+'/V2num_dict_train_train.csv')\n",
    "                V2num_dict = dict(zip(t_df['V_gene'], t_df['RBM_VU_id']))\n",
    "\n",
    "                train_2num_withVJ = add_VJ_info_2num(trainseq_2num, Vlist, Jlist, V2num_dict, J2num_dict)\n",
    "\n",
    "                print(train_2num_withVJ.shape)\n",
    "\n",
    "                if makeVJ:\n",
    "                    train_data = np.copy(train_2num_withVJ)\n",
    "                else:\n",
    "                    train_data = np.copy(train_2num_withVJ[:,:-2])\n",
    "\n",
    "                \n",
    "                filename_cdr3 = rootf + '/TCR_specificity_model/emerson_training_test/train_data_0_aligned_20.txt' \n",
    "                filename_cdr3raw = rootf + '/TCR_specificity_model/emerson_training_test/train_data_0.txt' \n",
    "\n",
    "                train_seq0=[]\n",
    "                with open(filename_cdr3) as f:\n",
    "                    for line in f:\n",
    "                        linesplit = line.strip().split('\\n')\n",
    "                        train_seq0.append(linesplit[0])\n",
    "\n",
    "                train_dataB_num = convert_number(train_seq0)\n",
    "\n",
    "                if makeVJ:\n",
    "                    ffraw = pd.read_csv(filename_cdr3raw,sep='\\t',header=None)\n",
    "                    VlistB = list(np.array(ffraw)[:,1])\n",
    "                    JlistB = list(np.array(ffraw)[:,2])\n",
    "                    train_2num_withVJ_B = add_VJ_info_2num(train_dataB_num, VlistB, JlistB, V2num_dict, J2num_dict)\n",
    "                    train_dataB = train_2num_withVJ_B[:Mb]\n",
    "                else:\n",
    "                    train_dataB = train_dataB_num[:Mb]\n",
    "\n",
    "                if makeVJ:\n",
    "                    n_cv = np.max(np.unique(train_dataB[:,-2])) + 1\n",
    "                else:\n",
    "                    n_cv=21\n",
    "\n",
    "                Mb=len(train_dataB)\n",
    "                pre_fields = utilities.average(train_dataB, c=n_cv)\n",
    "                fields_back, pwmB = regularized_pwm_torch(torch.from_numpy(pre_fields), 1/(fac*Mb), n_iter=npw)\n",
    "                if makefig:\n",
    "                    sequence_logo.Sequence_logo(utilities.average(train_data,c=n_cv))\n",
    "\n",
    "                decay_after = 0.5\n",
    "                N_MC = 10\n",
    "\n",
    "                batch_size = 2000\n",
    "                n_iter = 40\n",
    "\n",
    "                replB=0\n",
    "                name_back = 'backRBM-100hu-lowreg-'+ strVJ +'-train_train_WithoutDuplicates_repl'+str(replB)+'_' + str(Mb)\n",
    "                nameB = rootf + '/TCR_specificity_model/' +name_back +'.data'\n",
    "\n",
    "                mybackRBM = rbm.RBM(n_h = 100, n_v = len(train_dataB[0]),n_cv= n_cv, visible='Potts', hidden='dReLU',random_state = seed, zero_field = False)\n",
    "                if maketrainingB:\n",
    "                    mybackRBM.fit(train_dataB, weights = None, batch_size = batch_size, n_iter = n_iter, l1b = 0.001, l2_fields = l2f, N_MC = N_MC, decay_after = decay_after, verbose = 1, shuffle_data=False, CD=False)\n",
    "                    RBM_utils.saveRBM(nameB, mybackRBM)\n",
    "                nameB = rootf + '/TCR_specificity_model/' +name_back +'.data'\n",
    "\n",
    "                mybackRBM = RBM_utils.loadRBM(nameB)\n",
    "\n",
    "                Mt = len(train_data)\n",
    "                emp_freqsF = utilities.average(train_data, c=n_cv, weights = None)\n",
    "                fields_temp, pwmP = regularized_pwm_torch(torch.from_numpy(emp_freqsF), 1/(fac*Mt), n_iter= npw)\n",
    "\n",
    "                cont=[]\n",
    "                seqs=[]\n",
    "                for rl in range(len(cont0)):\n",
    "                    if type(cont0[rl])!=float:\n",
    "                        cont.append([int(r) for r in cont0[rl].split(' ')])                       \n",
    "                        seqs.append(seqs0[rl])\n",
    "\n",
    "                if make_unique_cont:\n",
    "                    seqs_u2=[]\n",
    "                    for N in range(len(seqs)):\n",
    "                        list2=''\n",
    "                        for c in cont[N]:\n",
    "                            list2 += str(c)\n",
    "                        seqs_u2.append(seqs[N] + list2)\n",
    "\n",
    "                    seqs_u3 = list(np.unique(seqs_u2))\n",
    "                    inds_u = [seqs_u2.index(s) for s in seqs_u3]\n",
    "\n",
    "                    seqs=[seqs[i] for i in inds_u]\n",
    "                    cont=[cont[i] for i in inds_u]\n",
    "\n",
    "                if make_unique:\n",
    "                    seqs_u = []\n",
    "                    count_u = []\n",
    "                    for ss in range(len(seqs)):\n",
    "                        if seqs[ss] not in seqs_u:\n",
    "                            seqs_u.append(seqs[ss])\n",
    "                            if seqs.count(seqs[ss])>1:\n",
    "                                hits = [i for i in range(len(seqs)) if seqs[i] == seqs[ss]]\n",
    "                                first=cont[ss]\n",
    "                                for y in hits:\n",
    "                                    ov = overlap_seqs(first,cont[y])\n",
    "                                    first = list(ov)\n",
    "                                count_u.append(ov)\n",
    "                            else:\n",
    "                                count_u.append(cont[ss])        \n",
    "                    seqs=seqs_u\n",
    "                    cont=count_u\n",
    "\n",
    "                seqs_n=convert_number(seqs)\n",
    "\n",
    "\n",
    "                learning_rate = None # default behaviour\n",
    "                decay_after = 0.5\n",
    "                N_MC = 10\n",
    "\n",
    "                if pep == 'YLQPRTFLL':\n",
    "                    bs = 16\n",
    "                else:\n",
    "                    bs = 100\n",
    "                if pep == 'NLVPMVATV': \n",
    "                    bs = 200\n",
    "                batch_size = bs\n",
    "\n",
    "                n_iter = int(2e4) // (train_data.shape[0] // bs)\n",
    "\n",
    "                n_h = 20\n",
    "                lib = 0.01\n",
    "\n",
    "                l2f_top= 1/Mt\n",
    "                l2f= 1/Mt\n",
    "\n",
    "                out_par0 = '_RW' + str(makeRW) + '_TR' + str(B) \n",
    "                out_par = '_nh' + str(n_h) + '_l12' + str(lib) + '_ZF' + str(ZF) + out_par0\n",
    "                name_top_lin = rootf + '/TCR_specificity_model/diffRBM_'+pep+'/models/topmodellin_test_contacts' + out_par + '.data'\n",
    "\n",
    "                postRBM = rbm.RBM(n_h = mybackRBM.n_h + n_h, n_v = mybackRBM.n_v, n_cv= mybackRBM.n_cv, visible='Potts', hidden='dReLU')\n",
    "                diffRBM = diffrbm.DiffRBM(mybackRBM, postRBM)\n",
    "                diffRBM.update_post_from_back(vlayer=True, hlayer=True)\n",
    "\n",
    "                if maketraining:\n",
    "                    diffRBM.fit_top(train_data, batch_size = batch_size, n_iter = n_iter, l1b = lib, l2_fields = l2f, l2_fields_top = 0, N_MC = N_MC, decay_after = decay_after, verbose = vv, vverbose = vv, batch_norm=True,callback = produce_callback_NOweights(diffRBM)) \n",
    "                    RBM_utils.saveRBM(name_top_lin, diffRBM)\n",
    "                    dRBM_lin = diffRBM\n",
    "\n",
    "                dRBM_lin = RBM_utils.loadRBM(name_top_lin)\n",
    "                RBM_back = dRBM_lin.RBMback\n",
    "                g_top_lin = dRBM_lin.top_rbm().vlayer.fields\n",
    "\n",
    "                l2f_top = 1/Mt\n",
    "                l2f= 1/Mt\n",
    "                postRBM = rbm.RBM(n_h = mybackRBM.n_h + n_h, n_v = mybackRBM.n_v, n_cv= mybackRBM.n_cv, visible='Potts', hidden='dReLU')\n",
    "                diffRBM = diffrbm.DiffRBM(mybackRBM, postRBM)\n",
    "                diffRBM.update_post_from_back(vlayer=True, hlayer=True)\n",
    "\n",
    "                name_top = rootf + '/TCR_specificity_model/diffRBM_'+pep+'/models/topmodel_test_contacts' + out_par + '.data'\n",
    "\n",
    "                if maketraining:\n",
    "                    diffRBM.fit_top(train_data, batch_size = batch_size, n_iter = n_iter, l1b = lib, l2_fields = l2f, l2_fields_top = 0, N_MC = N_MC, decay_after = decay_after, verbose = vv, vverbose = vv, batch_norm=True)\n",
    "                    RBM_utils.saveRBM(name_top, diffRBM)\n",
    "                    dRBM = diffRBM\n",
    "                dRBM = RBM_utils.loadRBM(name_top)\n",
    "\n",
    "                RBM_back = dRBM.RBMback\n",
    "                g_back = RBM_back.vlayer.fields\n",
    "                g_top = dRBM.top_rbm().vlayer.fields\n",
    "                g_post = dRBM.RBMpost.vlayer.fields\n",
    "                RBMq = dRBM.top_rbm()\n",
    "\n",
    "                SA=20\n",
    "                for N in range(len(seqs_n)):\n",
    "\n",
    "                    l10lin = [g_top_lin[i, seqs_n[N][i]] for i in range(SA) if seqs_n[N][i]!=20]\n",
    "\n",
    "                    hm = RBMq.hlayer.mean_from_inputs(RBMq.vlayer.compute_output(seqs_n[N], RBMq.weights, direction ='up'), beta = 1)\n",
    "                    I_top = RBMq.hlayer.compute_output(hm, RBMq.weights, direction='down')\n",
    "                    l10 = [g_top[i, seqs_n[N][i]] + sum(I_top[:,i, seqs_n[N][i]]) for i in range(SA) if seqs_n[N][i]!=20]\n",
    "\n",
    "                    hm = RBMq.hlayer.sample_from_inputs(RBMq.vlayer.compute_output(seqs_n[N], RBMq.weights, direction ='up') , beta = 1)\n",
    "\n",
    "                    I_top2 = RBMq.hlayer.compute_output(hm, RBMq.weights, direction='down')\n",
    "                    l1020 = site_conservation_scores(RBMq, seqs_n[N], A=21, L=len(seqs_n[N]))\n",
    "                    l102= [l1020[l] for l in range(len(l1020)) if seqs_n[N][l]!=20]\n",
    "\n",
    "                    l1.append(l10)\n",
    "                    l12.append(l102)\n",
    "                    l1lin.append(l10lin)\n",
    "\n",
    "                    posR.append(list(np.argsort(l10)[::-1] + 1))\n",
    "                    posRlin.append(list(np.argsort(l10lin)[::-1] + 1))\n",
    "                    posF.append(list(np.argsort(l102)[::-1] + 1))\n",
    "\n",
    "                    l1b0 = [fields_temp[i, seqs_n[N][i]] - fields_back[i, seqs_n[N][i]] for i in range(SA) if seqs_n[N][i]!=20]\n",
    "                    l1b.append(l1b0)\n",
    "\n",
    "                    l1b01 = [pwmP[i, seqs_n[N][i]] for i in range(SA) if seqs_n[N][i]!=20]\n",
    "\n",
    "                    l1b1.append(l1b01)\n",
    "\n",
    "                    posB1.append(list(np.argsort(l1b01)[::-1] + 1))\n",
    "\n",
    "                    posB.append(list(np.argsort(l1b0)[::-1] + 1))\n",
    "\n",
    "                    count+=1\n",
    "\n",
    "                ligands += list(seqs)\n",
    "                true_contacts_hla += list(cont)\n",
    "                if reweight_ppv:\n",
    "                    rws0 = utilities_diffrbm.compute_MSA_weights(seqs_n, threshold = th)\n",
    "                    rws_hla += list(rws0)\n",
    "\n",
    "            Leff = len(ligands)\n",
    "            if reweight_ppv:\n",
    "                Leff = sum(rws_hla)\n",
    "\n",
    "            SAl = np.min([len(posR[g]) for g in range(len(posR))])\n",
    "\n",
    "            s2=16\n",
    "            pos=np.copy(posR)\n",
    "            ppvR=[]\n",
    "            lm=[]\n",
    "            for u in range(SAl):\n",
    "                predP=0\n",
    "                for i in range(len(ligands)):\n",
    "                    fac=1\n",
    "                    if reweight_ppv:\n",
    "                        fac=rws_hla[i]\n",
    "                    ov = overlap_seqs(pos[i][:u+1], true_contacts_hla[i])\n",
    "                    if u==0 and len(ov)==0:\n",
    "                        lm.append(ligands[i])\n",
    "                    predP += fac*len(ov)/len(true_contacts_hla[i][:u+1])\n",
    "                ppvR.append(predP/Leff)\n",
    "\n",
    "            pos=np.copy(posRlin)\n",
    "            ppvRlin=[]\n",
    "            lm=[]\n",
    "            for u in range(SAl):\n",
    "                predP=0\n",
    "                for i in range(len(ligands)):\n",
    "                    fac=1\n",
    "                    if reweight_ppv:\n",
    "                        fac=rws_hla[i]\n",
    "                    ov = overlap_seqs(pos[i][:u+1], true_contacts_hla[i])\n",
    "                    if u==0 and len(ov)==0:\n",
    "                        lm.append(ligands[i])\n",
    "                    predP += fac*len(ov)/len(true_contacts_hla[i][:u+1])\n",
    "                ppvRlin.append(predP/Leff)\n",
    "\n",
    "            pos = np.copy(posB)\n",
    "            ppvB=[]\n",
    "            for u in range(SAl):\n",
    "                predP=0\n",
    "                for i in range(len(ligands)):\n",
    "                    fac=1\n",
    "                    if reweight_ppv:\n",
    "                        fac=rws_hla[i]\n",
    "                    ov = overlap_seqs(pos[i][:u+1], true_contacts_hla[i])\n",
    "                    predP += fac*len(ov)/len(true_contacts_hla[i][:u+1])\n",
    "                ppvB.append(predP/Leff)\n",
    "\n",
    "            pos = np.copy(posB1)\n",
    "            ppvB1=[]\n",
    "            for u in range(SAl):\n",
    "                predP=0\n",
    "                for i in range(len(ligands)):\n",
    "                    fac=1\n",
    "                    if reweight_ppv:\n",
    "                        fac=rws_hla[i]\n",
    "                    ov = overlap_seqs(pos[i][:u+1], true_contacts_hla[i])\n",
    "                    predP += fac*len(ov)/len(true_contacts_hla[i][:u+1])\n",
    "                ppvB1.append(predP/Leff)\n",
    "\n",
    "\n",
    "            pos = np.copy(posF)\n",
    "            ppvF=[]\n",
    "            for u in range(SAl):\n",
    "                predP=0\n",
    "                for i in range(len(ligands)):\n",
    "                    fac=1\n",
    "                    if reweight_ppv:\n",
    "                        fac=rws_hla[i]\n",
    "                    ov = overlap_seqs(pos[i][:u+1], true_contacts_hla[i])\n",
    "                    predP += fac*len(ov)/len(true_contacts_hla[i][:u+1])\n",
    "                ppvF.append(predP/Leff)\n",
    "\n",
    "            list_ppv_pwm.append(ppvB)\n",
    "            list_ppv_rbm.append(ppvR)\n",
    "\n",
    "            ppv_random_all=[]\n",
    "            for f in range(1000):\n",
    "                pos_random=[]\n",
    "                for u in range(len(ligands)):\n",
    "                    seq_random=list(np.arange(len([t for t in ligands[u] if t != '-']))+1)\n",
    "                    random.shuffle(seq_random)\n",
    "                    pos_random.append(seq_random)\n",
    "                pos = np.copy(pos_random)\n",
    "                ppv_random=[]\n",
    "                lm=[]\n",
    "                for u in range(SAl):\n",
    "                    predP=0\n",
    "                    for i in range(len(ligands)):\n",
    "                        fac=1\n",
    "                        if reweight_ppv:\n",
    "                            fac=rws_hla[i]\n",
    "                        ov = overlap_seqs(pos[i][:u+1], true_contacts_hla[i])\n",
    "\n",
    "                        predP += fac*len(ov)/len(true_contacts_hla[i][:u+1])\n",
    "                    ppv_random.append(predP/Leff)\n",
    "                ppv_random_all.append(ppv_random)\n",
    "            ppv_random = np.mean(ppv_random_all,axis=0)\n",
    "\n",
    "            if print_table:\n",
    "                datao = {\n",
    "                'Random': ppv_random,\n",
    "                'Frequency': ppvB1,\n",
    "                'diffPWM': ppvB,\n",
    "                'topRBM (lin)': ppvRlin,\n",
    "                'topRBM2': ppvF,\n",
    "                'topRBM1': ppvR\n",
    "                }\n",
    "\n",
    "                df = pd.DataFrame(datao, columns = ['Random','Frequency', 'diffPWM', 'topRBM (lin)', 'topRBM2', 'topRBM1'])\n",
    "                df.to_csv(rootf + '/TCR_specificity_model/Results/prediction_contacts_ang' + str(TH) + '_pep' + pepN + '_rew' + str(th) + '.tsv', sep='\\t')\n",
    "\n",
    "            cont = true_contacts_hla;\n",
    "            cont_R=[]\n",
    "            for c in range(len(cont)):\n",
    "                cont_R.append(list(np.array(cont[c])-len(l1[c])-1))\n",
    "\n",
    "            freqs_R=[]\n",
    "            sym_R=[]\n",
    "            for u in range(-SA,0):\n",
    "                cou=0\n",
    "                sym_R.append(u)\n",
    "                for cc in range(len(cont_R)):\n",
    "                    fac=1\n",
    "                    if reweight_ppv:\n",
    "                        fac = rws_hla[cc]\n",
    "                    cou+=fac*cont_R[cc].count(u+1)\n",
    "                freqs_R.append(cou/Leff)\n",
    "\n",
    "            freqs=[]\n",
    "            sym=[]\n",
    "            for u in range(SA):\n",
    "                cou=0\n",
    "                sym.append(u+1)\n",
    "                for cc in range(len(cont)):\n",
    "                    fac=1\n",
    "                    if reweight_ppv:\n",
    "                        fac = rws_hla[cc]\n",
    "                    cou+=fac*cont[cc].count(u+1)\n",
    "                freqs.append(cou/Leff)\n",
    "\n",
    "            l1ave_R=[]\n",
    "            l1bave_R=[]\n",
    "            for j in range(-SA,0):\n",
    "                l1_temp = [l1[l] for l in range(len(l1)) if j + len(l1[l]) + 1 > 0 and len(l1[l]) > j + len(l1[l]) + 1 ]\n",
    "                l1b_temp = [l1b[l] for l in range(len(l1b)) if j + len(l1[l]) + 1 > 0 and len(l1b[l]) > j + len(l1[l]) + 1]\n",
    "                if len(l1_temp):\n",
    "                    l1ave_R.append(sum([l[j + len(l) + 1] for l in l1_temp])/len(l1_temp))\n",
    "                    l1bave_R.append(sum([l[j + len(l) + 1] for l in l1b_temp])/len(l1b_temp))\n",
    "\n",
    "            l1ave=[]\n",
    "            l1bave=[]\n",
    "            for i in range(SA):\n",
    "                l1_temp = [l1[l] for l in range(len(l1)) if len(l1[l]) > i]\n",
    "                l1b_temp = [l1b[l] for l in range(len(l1b)) if len(l1b[l]) > i]\n",
    "                if len(l1_temp):\n",
    "                    l1ave.append(sum([l[i] for l in l1_temp])/len(l1_temp))\n",
    "                    l1bave.append(sum([l[i] for l in l1b_temp])/len(l1b_temp))\n",
    "\n",
    "\n",
    "\n",
    "            if print_table and TH==4 and Pi==0 and RP==1:\n",
    "                datao = {\n",
    "                'sym': sym[:len(l1ave)],\n",
    "                'freqs': freqs[:len(l1ave)],\n",
    "                'pred_diffpwm': l1bave,\n",
    "                'pred_rbm': l1ave\n",
    "                }\n",
    "                df = pd.DataFrame(datao, columns = ['sym', 'freqs', 'pred_diffpwm', 'pred_rbm'])\n",
    "                df.to_csv(rootf + '/TCR_specificity_model/Results/frequency_contacts_ang' + str(TH) + '_rew' + str(th) + '.tsv', sep='\\t')\n",
    "                datao = {\n",
    "                'sym_R': sym_R[-len(l1ave_R):],\n",
    "                'freqs_R': freqs_R[-len(l1ave_R):],\n",
    "                'pred_diffpwm_R': l1bave_R,\n",
    "                'pred_rbm_R': l1ave_R\n",
    "                }\n",
    "                df = pd.DataFrame(datao, columns = ['sym_R', 'freqs_R', 'pred_diffpwm_R', 'pred_rbm_R'])\n",
    "                df.to_csv(rootf + '/TCR_specificity_model/Results/frequency_contacts_ang' + str(TH) + '_rew' + str(th) + '_R.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
